{
    "name": "root",
    "gauges": {
        "PlayerBehaviour.Policy.Entropy.mean": {
            "value": 1.2496434450149536,
            "min": 1.2479193210601807,
            "max": 1.4189379215240479,
            "count": 20
        },
        "PlayerBehaviour.Policy.Entropy.sum": {
            "value": 14558.345703125,
            "min": 14558.345703125,
            "max": 19439.44921875,
            "count": 20
        },
        "PlayerBehaviour.Environment.EpisodeLength.mean": {
            "value": 91.3923076923077,
            "min": 62.31578947368421,
            "max": 91.3923076923077,
            "count": 20
        },
        "PlayerBehaviour.Environment.EpisodeLength.sum": {
            "value": 11881.0,
            "min": 11720.0,
            "max": 12035.0,
            "count": 20
        },
        "PlayerBehaviour.Step.mean": {
            "value": 239968.0,
            "min": 11986.0,
            "max": 239968.0,
            "count": 20
        },
        "PlayerBehaviour.Step.sum": {
            "value": 239968.0,
            "min": 11986.0,
            "max": 239968.0,
            "count": 20
        },
        "PlayerBehaviour.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.6447969675064087,
            "min": -2.8034446239471436,
            "max": 0.09037560969591141,
            "count": 20
        },
        "PlayerBehaviour.Policy.ExtrinsicValueEstimate.sum": {
            "value": -83.8236083984375,
            "min": -501.81658935546875,
            "max": 17.080989837646484,
            "count": 20
        },
        "PlayerBehaviour.Environment.CumulativeReward.mean": {
            "value": 1.375640699496636,
            "min": -5.274250568536224,
            "max": 1.375640699496636,
            "count": 20
        },
        "PlayerBehaviour.Environment.CumulativeReward.sum": {
            "value": 178.83329093456268,
            "min": -996.8333574533463,
            "max": 178.83329093456268,
            "count": 20
        },
        "PlayerBehaviour.Policy.ExtrinsicReward.mean": {
            "value": 1.375640699496636,
            "min": -5.274250568536224,
            "max": 1.375640699496636,
            "count": 20
        },
        "PlayerBehaviour.Policy.ExtrinsicReward.sum": {
            "value": 178.83329093456268,
            "min": -996.8333574533463,
            "max": 178.83329093456268,
            "count": 20
        },
        "PlayerBehaviour.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "PlayerBehaviour.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "PlayerBehaviour.Losses.PolicyLoss.mean": {
            "value": 0.1017378933614164,
            "min": 0.09537649940684398,
            "max": 0.10497346414284735,
            "count": 19
        },
        "PlayerBehaviour.Losses.PolicyLoss.sum": {
            "value": 0.1017378933614164,
            "min": 0.09537649940684398,
            "max": 0.10497346414284735,
            "count": 19
        },
        "PlayerBehaviour.Losses.ValueLoss.mean": {
            "value": 3.219554772613742,
            "min": 1.6739968841380262,
            "max": 3.4497157592399446,
            "count": 19
        },
        "PlayerBehaviour.Losses.ValueLoss.sum": {
            "value": 3.219554772613742,
            "min": 1.6739968841380262,
            "max": 3.4497157592399446,
            "count": 19
        },
        "PlayerBehaviour.Policy.LearningRate.mean": {
            "value": 0.000298626132457956,
            "min": 0.000298626132457956,
            "max": 0.00029992782002406,
            "count": 19
        },
        "PlayerBehaviour.Policy.LearningRate.sum": {
            "value": 0.000298626132457956,
            "min": 0.000298626132457956,
            "max": 0.00029992782002406,
            "count": 19
        },
        "PlayerBehaviour.Policy.Epsilon.mean": {
            "value": 0.199542044,
            "min": 0.199542044,
            "max": 0.19997594000000005,
            "count": 19
        },
        "PlayerBehaviour.Policy.Epsilon.sum": {
            "value": 0.199542044,
            "min": 0.199542044,
            "max": 0.19997594000000005,
            "count": 19
        },
        "PlayerBehaviour.Policy.Beta.mean": {
            "value": 0.0009954662356,
            "min": 0.0009954662356,
            "max": 0.0009997618059999999,
            "count": 19
        },
        "PlayerBehaviour.Policy.Beta.sum": {
            "value": 0.0009954662356,
            "min": 0.0009954662356,
            "max": 0.0009997618059999999,
            "count": 19
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1711904993",
        "python_version": "3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\nivle\\anaconda3\\envs\\mlagent_py3-9\\Scripts\\mlagents-learn ./BasicConfig.yaml --run-id timed1",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1711905405"
    },
    "total": 412.3341034,
    "count": 1,
    "self": 0.005198800000073334,
    "children": {
        "run_training.setup": {
            "total": 0.06862520000000005,
            "count": 1,
            "self": 0.06862520000000005
        },
        "TrainerController.start_learning": {
            "total": 412.26027939999994,
            "count": 1,
            "self": 0.15936850000076674,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.0314925,
                    "count": 1,
                    "self": 8.0314925
                },
                "TrainerController.advance": {
                    "total": 403.86362019999916,
                    "count": 7334,
                    "self": 0.144159799999386,
                    "children": {
                        "env_step": {
                            "total": 168.5209648999997,
                            "count": 7334,
                            "self": 133.5616339999991,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 34.86758430000073,
                                    "count": 7334,
                                    "self": 0.397864900001089,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 34.46971939999964,
                                            "count": 4867,
                                            "self": 34.46971939999964
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.0917465999998921,
                                    "count": 7333,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 332.5931975999998,
                                            "count": 7333,
                                            "is_parallel": true,
                                            "self": 272.64801060000207,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0008876999999998247,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00031410000000064997,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0005735999999991748,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0005735999999991748
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 59.944299299997745,
                                                    "count": 7333,
                                                    "is_parallel": true,
                                                    "self": 1.4254950999967875,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 4.440000699998659,
                                                            "count": 7333,
                                                            "is_parallel": true,
                                                            "self": 4.440000699998659
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 50.83981510000168,
                                                            "count": 7333,
                                                            "is_parallel": true,
                                                            "self": 50.83981510000168
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 3.2389884000006255,
                                                            "count": 7333,
                                                            "is_parallel": true,
                                                            "self": 1.4235082000009136,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.8154801999997119,
                                                                    "count": 14666,
                                                                    "is_parallel": true,
                                                                    "self": 1.8154801999997119
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 235.1984955000001,
                            "count": 7333,
                            "self": 0.5370353999992687,
                            "children": {
                                "process_trajectory": {
                                    "total": 19.962007600000813,
                                    "count": 7333,
                                    "self": 19.962007600000813
                                },
                                "_update_policy": {
                                    "total": 214.6994525,
                                    "count": 20,
                                    "self": 27.046223900001365,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 187.65322859999864,
                                            "count": 11274,
                                            "self": 187.65322859999864
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.20579820000000382,
                    "count": 1,
                    "self": 0.0009334000000080778,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.20486479999999574,
                            "count": 1,
                            "self": 0.20486479999999574
                        }
                    }
                }
            }
        }
    }
}